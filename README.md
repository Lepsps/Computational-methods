
Вот список страниц лекций (из первых 49 изображений), на которых находится материал для каждого билета:

*   **Билет 1** (Корректность, Интерполяция Лагранжа): **Стр. 1, 2, 3**
*   **Билет 2** (Полином Ньютона): **Стр. 4, 5**
*   **Билет 3** (Оценка погрешности, Полиномы Чебышёва): **Стр. 6, 7** (погрешность), **Стр. 13, 14, 15** (Чебышёв)
*   **Билет 4** (МНК, Кубические сплайны): **Стр. 8** (МНК), **Стр. 9, 10, 11** (Сплайны)
*   **Билет 5** (Метрические пространства, Сжимающие отображения): **Стр. 18–23** (Метрики), **Стр. 24, 25** (Сжимающие отображения)
*   **Билет 6** (Итерации, Обусловленность, Зейдель): **Стр. 25** (Итерации), **Стр. 26, 27** (Обусловленность), **Стр. 28, 29** (Зейдель)
*   **Билет 7** (Метод прогонки, Задача о назначениях): **Стр. 30, 31** (Прогонка), **Стр. 31, 32, 33** (Назначения)
*   **Билет 8** (Интегрирование, Ньютон-Котес, АСТ): **Стр. 33, 34, 35** (Прямоугольники), **Стр. 36, 37** (Ньютон-Котес), **Стр. 38, 39** (АСТ)
*   **Билет 9** (Остаточный член, Рунге): **Стр. 40, 41, 42** (Остаточный член), **Стр. 44, 45** (Рунге)
*   **Билет 10** (Ортогональные многочлены, Гаусс): **Стр. 46, 47** (Лежандр), **Стр. 48** (Гаусс)
*   **Билет 11** (Полином Эрмита): **Стр. 16, 17**
*   **Билет 12** (Вывод погрешностей дифференцированием по параметру): **Стр. 49**
*   **Билет 13** (Свойства сплайнов): **Стр. 12**
*   **Билет 14** (Многочлены Лежандра, Нелинейные уравнения): **Стр. 47** (Лежандр), **Стр. 49** (Нелинейные ур. и Собственные числа)
*   **Билет 15** (Методы прямоугольников): **Стр. 34, 35**
*   **Билет 16** (Интерполяционные формулы / Ньютона-Котеса): **Стр. 36, 37**
*   **Билет 17** (Алгебраическая степень точности): **Стр. 38, 39**
*   **Билет 18** (Остаточный член квадратур): **Стр. 40, 41**
*   **Билет 19** (Правило Рунге): **Стр. 44, 45**
*   **Билет 20** (Ортогональные многочлены): **Стр. 46, 47**
*   **Билет 21** (Формулы Гаусса): **Стр. 48**
*   **Билет 22** (Детальный вывод погрешностей): **Стр. 49**
*   **Билет 23** (Собственные числа и Нелинейные уравнения): **Стр. 49** (нижняя часть и правый столбец)

---
### Билет 1. Понятие корректности задачи и Интерполяция Лагранжа

**1. Корректность задачи (по Адамару)**
С точки зрения вычислительной математики задача называется **корректной**, если выполняются три условия:
1.  **Существование:** Решение задачи существует для рассматриваемого класса данных.
2.  **Единственность:** Решение единственно.
3.  **Устойчивость:** Малому изменению начальных данных соответствует малое изменение выходных данных (решения).

*Пример:*
*   *Интегрирование* — корректная задача. $\tilde{I} - I = \int (f+\delta) - \int f = \int \delta \le (b-a) \cdot \max|\delta|$. Ошибка ограничена константой.
*   *Дифференцирование* — некорректная задача.
    Рассмотрим $f(x) = \frac{1}{N} \sin(N^2 x)$.
    При $N \to \infty$, $|f(x)| \le \frac{1}{N} \to 0$ (малое возмущение).
    Производная: $f'(x) = N \cos(N^2 x)$. Амплитуда производной равна $N \to \infty$.
    Малое изменение функции привело к бесконечно большому изменению производной (нарушена устойчивость).

**2. Задача интерполяции. Полином Лагранжа**
*Постановка:* Дано $n$ точек $(x_i, y_i)$. Требуется найти полином $P(x)$ степени не выше $n-1$, такой что $P(x_i) = y_i$.
*Решение:*
Интерполяционный полином Лагранжа строится как линейная комбинация базисных полиномов:
$$P_{n-1}(x) = \sum_{i=1}^n y_i L_i(x)$$
Базисный полином $L_i(x)$ обладает свойством: $L_i(x_i) = 1$, а во всех остальных узлах $L_i(x_j) = 0$ ($j \ne i$).
Явный вид:
$$L_i(x) = \prod_{j=1, j\ne i}^n \frac{x - x_j}{x_i - x_j}$$
*Недостаток:* При добавлении нового узла интерполяции приходится пересчитывать все базисные полиномы заново.

---

### Билет 2. Интерполяционный полином Ньютона (с доказательством)

Полином Ньютона позволяет добавлять новые узлы без полного пересчета предыдущих вычислений.

**1. Разделенная разность**
Вводится понятие разделенной разности:
*   Нулевого порядка: $f(x_i)$.
*   Первого порядка: $f(x_1; x_2) = \frac{f(x_2) - f(x_1)}{x_2 - x_1}$.
*   Второго порядка: $f(x_1; x_2; x_3) = \frac{f(x_2; x_3) - f(x_1; x_2)}{x_3 - x_1}$.
*   $n$-го порядка: рекурсивно через разности $(n-1)$-го порядка.

**2. Формула полинома Ньютона**
Для $n$ точек полином имеет вид:
$$P_{n-1}(x) = f(x_1) + f(x_1; x_2)(x-x_1) + f(x_1; x_2; x_3)(x-x_1)(x-x_2) + \dots$$
В общем виде (для $k$ слагаемых):
$$P_k(x) = P_{k-1}(x) + f(x_1; \dots; x_{k+1}) \cdot \prod_{j=1}^k (x - x_j)$$

**3. Доказательство (метод математической индукции)**
*   *База ($n=2$):*
    $P_1(x) = f(x_1) + \frac{f(x_2)-f(x_1)}{x_2-x_1}(x-x_1)$.
    Проверка: $P_1(x_1) = f(x_1)$, $P_1(x_2) = f(x_2)$ — верно.
*   *Предположение:* Формула верна для $k$ точек ($P_{k-1}$).
*   *Шаг:* Добавляем точку $(x_{k+1}, y_{k+1})$. Ищем $P_k(x)$ в виде $P_{k-1}(x) + C \cdot (x-x_1)\dots(x-x_k)$.
    В точках $x_1 \dots x_k$ равенство выполняется автоматически.
    Нужно, чтобы $P_k(x_{k+1}) = f(x_{k+1})$.
    Отсюда выводится, что коэффициент $C$ равен разделенной разности $f(x_1; \dots; x_{k+1})$.
    (В лекциях приведено подробное алгебраическое преобразование разности двух полиномов для доказательства тождества коэффициента).

---

### Билет 3. Оценка погрешности интерполяции и Полиномы Чебышёва

**1. Оценка погрешности**
Пусть $f(x) \in C^n[a, b]$ (имеет $n$ непрерывных производных).
Погрешность интерполяции $e(x) = f(x) - P_{n-1}(x)$ оценивается формулой:
$$|f(x) - P_{n-1}(x)| \le \frac{M_n}{n!} |\omega_n(x)|$$
где $M_n = \max_{t \in [a,b]} |f^{(n)}(t)|$, а $\omega_n(x) = (x-x_1)(x-x_2)\dots(x-x_n)$.

*Доказательство:*
Вводится вспомогательная функция $\varphi(t) = \omega(t) \cdot e(x) - \omega(x) \cdot e(t)$ (где $x$ — фиксированная точка ошибки).
Функция $\varphi(t)$ имеет $n+1$ корень (узлы + точка $x$). По теореме Ролля, её $n$-я производная имеет хотя бы 1 корень $\xi$.
Так как $P^{(n)}(x) = 0$, то $e^{(n)}(t) = f^{(n)}(t)$. Из уравнения $\varphi^{(n)}(\xi) = 0$ получаем выражение для $e(x)$.

**2. Полиномы Чебышёва**
Вопрос: Как выбрать узлы $x_i$, чтобы минимизировать погрешность?
Нужно минимизировать $|\omega_n(x)|$.
Наилучшим полиномом (наименее уклоняющимся от нуля на $[-1, 1]$) является нормированный полином Чебышёва $\tilde{T}_n(x) = \frac{1}{2^{n-1}} T_n(x)$.
$$T_n(x) = \cos(n \arccos x)$$
*Свойства:*
1.  Старший коэффициент $2^{n-1}$.
2.  Корни на $[-1, 1]$ вычисляются по формуле: $x_k = \cos \frac{\pi(2k+1)}{2n}$.
3.  Максимальное значение модуля $|T_n(x)| \le 1$.

Если выбрать узлы интерполяции в корнях полинома Чебышёва, погрешность будет минимально возможной для данного $n$. Для произвольного отрезка $[a, b]$ делается линейное преобразование переменных.

---

### Билет 4. Кубические сплайны и Метод наименьших квадратов

**1. Метод наименьших квадратов (МНК)**
Применяется, когда нужно приблизить облако точек некоторой гладкой функцией (например, прямой $y=ax+b$), не проходящей строго через точки, но минимизирующей общую ошибку.
Критерий качества:
$$J = \sum_{i=1}^n (y_i - (ax_i + b))^2 \to \min$$
Для минимизации берем частные производные по $a$ и $b$ и приравниваем к нулю: $\frac{\partial J}{\partial a} = 0, \frac{\partial J}{\partial b} = 0$.
Это приводит к системе линейных уравнений (СЛАУ) относительно $a$ и $b$, которая называется системой нормальных уравнений. Определитель этой системы (определитель Грама) отличен от нуля (если точки различны), решение единственно.

**2. Кубический сплайн**
Сплайн $S(x)$ — это функция, которая на каждом отрезке $[x_i, x_{i+1}]$ является кубическим полиномом, а в узлах $x_i$ непрерывна сама функция, её первая и вторая производные ($S \in C^2$).
В узлах: $S(x_i) = y_i$.

*Построение:*
Обозначим $M_i = S''(x_i)$. Так как сплайн кубический, вторая производная линейна на отрезке. Выражаем $S''(x)$ через $M_i$ и $M_{i+1}$.
Дважды интегрируем, получаем выражение для $S(x)$ с константами.
Константы находим из условий сшивки первых производных $S'_{i-1}(x_i) = S'_i(x_i)$.
Это приводит к системе уравнений относительно моментов $M_i$:
$$\mu_i M_{i-1} + 2 M_i + \lambda_i M_{i+1} = d_i$$
Матрица системы — трехдиагональная. Решается методом прогонки.
*Граничные условия:* Часто полагают $M_0 = M_n = 0$ (естественный сплайн).

---

### Билет 5. Метрические пространства и Неподвижная точка

**1. Метрическое пространство**
Пара $\{M, \rho\}$, где $M$ — множество элементов, $\rho$ — метрика (расстояние).
Аксиомы метрики:
1.  $\rho(x, y) \ge 0$.
2.  $\rho(x, y) = 0 \iff x=y$.
3.  $\rho(x, y) = \rho(y, x)$.
4.  $\rho(x, y) \le \rho(x, z) + \rho(z, y)$ (неравенство треугольника).

*Примеры:*
*   Евклидово $R^n$: $\rho = \sqrt{\sum (x_i - y_i)^2}$.
*   Пространство непрерывных функций $C[a, b]$ с чебышёвской метрикой: $\rho(f, g) = \max |f(x) - g(x)|$.
*   Интегральная метрика $\int |f-g| dx$.

**2. Полнота и сходимость**
*   Последовательность $\{x_n\}$ **сходится** к $x_0$, если $\rho(x_n, x_0) \to 0$.
*   Последовательность **фундаментальна**, если $\forall \epsilon > 0 \exists N: \forall n,m > N \Rightarrow \rho(x_n, x_m) < \epsilon$.
*   Пространство **полное**, если любая фундаментальная последовательность сходится к элементу этого же пространства. (Пример полного: $R^n$, $C[a, b]$ c max-метрикой. Пример неполного: $C[a, b]$ с интегральной метрикой).

**3. Принцип сжимающих отображений**
Отображение $A$ называется сжимающим, если $\rho(Ax, Ay) \le q \cdot \rho(x, y)$, где $0 \le q < 1$.
**Теорема:** В полном метрическом пространстве сжимающее отображение имеет **единственную** неподвижную точку $x^*$ ($Ax^* = x^*$).
Итерационный процесс $x_{n+1} = Ax_n$ сходится к $x^*$ при любом начальном $x_0$.
Скорость сходимости оценивается через геометрическую прогрессию: $\rho(x_n, x^*) \le \frac{q^n}{1-q} \rho(x_1, x_0)$.

---

### Билет 6. Решение СЛАУ (Итерационные методы)

**1. Метод простой итерации**
Для решения $Ax=b$ систему преобразуют к виду $x = Bx + c$.
Алгоритм: $x^{(k+1)} = B x^{(k)} + c$.
Условие сходимости: $||B|| < 1$ (любая каноническая норма матрицы).
Достаточное условие сходимости для исходной матрицы $A$ — **диагональное преобладание**: $|a_{ii}| > \sum_{j \ne i} |a_{ij}|$.

**2. Число обусловленности**
Характеризует зависимость погрешности решения от погрешности входных данных.
$$\mu(A) = ||A|| \cdot ||A^{-1}||$$
Оценка относительной погрешности:
$$\frac{||\Delta x||}{||x||} \le \mu(A) \frac{||\Delta b||}{||b||}$$
Если $\mu(A)$ велико — система *плохо обусловлена* (малая ошибка в данных дает огромную ошибку в ответе). Оптимально $\mu(A) = 1$ (для ортогональных матриц).

**3. Метод Зейделя**
Модификация метода простой итерации. При вычислении $(k+1)$-го приближения для переменной $x_i$ используются уже найденные на этом же шаге значения $x_1^{(k+1)}, \dots, x_{i-1}^{(k+1)}$.
Формально: матрица $A$ разбивается на $L$ (нижнюю), $D$ (диагональ), $U$ (верхнюю).
Итерация: $(L+D)x^{(k+1)} = b - U x^{(k)}$.
Обычно сходится быстрее метода простой итерации.

---

### Билет 7. Метод прогонки и Задача о назначениях

**1. Метод прогонки**
Применяется для решения СЛАУ с **трехдиагональной матрицей**:
$A_i x_{i-1} + C_i x_i + B_i x_{i+1} = F_i$.
Суть: ищем решение в виде $x_i = \alpha_{i+1} x_{i+1} + \beta_{i+1}$.
*Прямой ход (сверху вниз):* вычисляем прогоночные коэффициенты $\alpha$ и $\beta$.
$$\alpha_{i+1} = \frac{-B_i}{A_i \alpha_i + C_i}, \quad \beta_{i+1} = \frac{F_i - A_i \beta_i}{A_i \alpha_i + C_i}$$
*Обратный ход (снизу вверх):* находим $x_n$ из граничного условия, затем восстанавливаем все $x_i$ по формуле линейной связи.
Сложность $O(n)$. Устойчив, если $|C_i| \ge |A_i| + |B_i|$.

**2. Задача о назначениях**
Дана матрица весов $C_{n \times n}$. Нужно выбрать $n$ элементов (по одному в каждой строке и столбце) так, чтобы их сумма была минимальна.
$X_{ij} = 1$, если назначение выбрано, 0 иначе. $\sum X_{ij} C_{ij} \to \min$.
*Метод решения:*
Если из строки или столбца вычесть константу, оптимальное решение (набор позиций) не изменится.
Цель: преобразовать матрицу (вычитая минимумы из строк и столбцов) так, чтобы получить достаточно нулей. Оптимальное назначение выбирается по позициям нулей.
Если нужно найти *максимум*, переходим к матрице $\tilde{C}_{ij} = \max(C) - C_{ij}$ и ищем минимум.

---

### Билет 8. Численное интегрирование (Квадратурные формулы)

Задача: вычислить $I = \int_a^b f(x) dx \approx \sum_{k=0}^n w_k f(x_k)$.
$x_k$ — узлы, $w_k$ — веса.

**1. Формулы прямоугольников**
*   Левых: $\approx (b-a) f(a)$. Точность $O(h)$.
*   Правых: $\approx (b-a) f(b)$. Точность $O(h)$.
*   Средних: $\approx (b-a) f(\frac{a+b}{2})$. Точность $O(h^2)$ (выше за счет симметрии).

**2. Формулы Ньютона-Котеса (равномерная сетка)**
Строятся путем замены $f(x)$ на интерполяционный полином Лагранжа.
*   **Формула трапеций (по 2 точкам):**
    $$I \approx \frac{b-a}{2} (f(a) + f(b))$$
    Алгебраическая степень точности $m=1$.
*   **Формула Симпсона (по 3 точкам):**
    Узлы: $a, \frac{a+b}{2}, b$. Замена на параболу.
    $$I \approx \frac{b-a}{6} \left( f(a) + 4f\left(\frac{a+b}{2}\right) + f(b) \right)$$
    Алгебраическая степень точности $m=3$ (точна для кубических многочленов).

**3. Алгебраическая степень точности (АСТ)**
Число $m$ такое, что формула точна для любого полинома степени $\le m$ и не точна для $x^{m+1}$.
Для формул Ньютона-Котеса с $n$ узлами: если $n$ нечетное, АСТ = $n$, если четное — АСТ = $n+1$ (эффект повышения точности).

---

### Билет 9. Погрешность интегрирования и Правило Рунге

**1. Остаточный член $R(f)$**
Погрешность выводится через разложение в ряд Тейлора или через ядро Пеано.
*   Для формулы **средних прямоугольников**: $R = \frac{(b-a)^3}{24} f''(\xi)$.
*   Для формулы **трапеций**: $R = -\frac{(b-a)^3}{12} f''(\xi)$.
*   Для формулы **Симпсона**: $R = -\frac{(b-a)^5}{2880} f^{(4)}(\xi)$ (очень высокая точность для гладких функций).

Для составных формул (весь отрезок разбит на $N$ шагов длины $h$) порядок погрешности снижается на единицу степени длины отрезка, но выражается через шаг $h$:
Трапеции: $O(h^2)$. Симпсон: $O(h^4)$.

**2. Правило Рунге (Апостериорная оценка)**
Позволяет оценить ошибку, имея результаты вычислений на двух сетках: с шагом $h$ ($I_h$) и с шагом $h/2$ ($I_{h/2}$).
Предполагая, что главная часть погрешности имеет вид $C \cdot h^p$ (где $p$ — порядок метода), получаем:
$$R_{h/2} \approx \frac{I_{h/2} - I_h}{2^p - 1}$$
Это значение добавляют к $I_{h/2}$ для уточнения результата (Рунге-Ромберг).
Также можно контролировать реальный порядок сходимости: $p^* = \log_2 \frac{I_{h} - I_{h/2}}{I_{h/2} - I_{h/4}}$.

---

### Билет 10. Квадратурные формулы Гаусса

**1. Идея метода**
В отличие от формул Ньютона-Котеса, где узлы фиксированы, в методе Гаусса узлы $x_k$ и веса $w_k$ подбираются так, чтобы максимизировать алгебраическую степень точности (АСТ).
У формулы с $N$ узлами имеется $2N$ свободных параметров ($N$ узлов + $N$ весов).
Следовательно, можно точно интегрировать многочлены степени $2N-1$.

**2. Ортогональные многочлены**
Узлы квадратурной формулы Гаусса должны быть **корнями ортогонального многочлена** степени $N$ на интервале интегрирования.
Для стандартного отрезка $[-1, 1]$ это **полиномы Лежандра** $L_n(x)$.
*Свойства:* $\int_{-1}^1 L_n(x) L_m(x) dx = 0$ при $n \ne m$.

**3. Построение**
1. Находим корни полинома Лежандра $n$-й степени — это узлы $x_k$.
2. Веса $w_k$ находим из условия точности для базисных мономов $1, x, \dots, x^{n-1}$ (решая СЛАУ).
Для $N=2$ узлы $\pm \frac{1}{\sqrt{3}}$, веса $1$. АСТ = 3.

**4. Остаточный член**
Для формулы Гаусса с $n$ узлами:
$$E[f] = \frac{f^{(2n)}(\xi)}{(2n)!} \int \omega_n^2(x) dx$$
Содержит производную порядка $2n$, что обеспечивает огромную точность для гладких функций даже при малом числе узлов.

---

### Билет 11. Интерполяционный полином Эрмита

**1. Постановка задачи**
В отличие от классической интерполяции Лагранжа/Ньютона, где заданы только значения функции $y_i = f(x_i)$, в задаче Эрмита в узлах заданы значения функции **и её производных** до некоторого порядка.
Частный случай: заданы значения $y_i$ и первой производной $y'_i$ во всех точках $i = 1, \dots, n$.

**2. Построение полинома**
Пусть $P_{n-1}(x)$ — полином, проходящий через точки $(x_i, y_i)$ (интерполяционный полином Лагранжа).
Полином Эрмита $E_m(x)$ ищется в виде:
$$E_m(x) = P_{n-1}(x) + (x-x_1)(x-x_2)\dots(x-x_n) \cdot Z(x)$$
где $Z(x)$ — неизвестная функция (корректирующий полином).
Обозначим $\omega_n(x) = \prod_{j=1}^n (x-x_j)$.
Тогда условие на значения $E_m(x_i) = y_i$ выполняется автоматически (так как второе слагаемое обнуляется).
Условие на производные:

$$E'_m(x_i) = P'_{n-1}(x_i) + \omega'_n(x_i) \cdot Z(x_i) = y'_i$$

Отсюда выражается $Z(x_i)$:

$$Z(x_i) = \frac{y'_i - P'_{n-1}(x_i)}{\omega'_n(x_i)}$$

Таким образом, задача сводится к нахождению полинома $Z(x)$, интерполирующего полученные значения.
Итоговая формула для полинома Эрмита (с кратными узлами) имеет степень $2n-1$.

**3. Оценка погрешности**
Так как в каждом узле совпадают и значение, и производная, то корень $(x-x_i)$ входит в остаточный член в квадрате.
$$|f(x) - H(x)| \le \frac{M_{2n}}{(2n)!} (x-x_1)^2 (x-x_2)^2 \dots (x-x_n)^2$$

---

### Билет 12. Вывод формул погрешности интегрирования (Метод дифференцирования по параметру)

В лекциях приведен подробный аналитический вывод остаточных членов, основанный на введении функции ошибки от параметра шага $R(h)$.

**1. Вывод для формулы средней точки**
Рассматриваем интеграл $I = \int_{a}^{b} f(x) dx$ и приближение $I_{cp} = f(\frac{a+b}{2})(b-a)$.
Вводим переменную $h = \frac{b-a}{2}$, центр $\theta = \frac{a+b}{2}$.
Ошибка $R(h) = \int_{\theta-h}^{\theta+h} f(t) dt - 2h f(\theta)$.
1.  $R(0) = 0$.
2.  Дифференцируем по $h$: $R'(h) = (F(\theta+h) - F(\theta-h))' - 2f(\theta) = f(\theta+h) + f(\theta-h) - 2f(\theta)$.
    $R'(0) = 0$.
3.  Вторая производная: $R''(h) = f'(\theta+h) - f'(\theta-h)$.
    По теореме Лагранжа: $R''(h) = f''(\xi) \cdot (\theta+h - (\theta-h)) = f''(\xi) \cdot 2h$.
4.  Интегрируя обратно или используя ряд Тейлора для $R(h)$ при $R(0)=R'(0)=0$:
    $$R(h) \approx \frac{1}{2} R''(\xi_1) h^2 \approx \frac{1}{2} (2h f''(\xi)) \cdot \text{множитель}$$
    В итоге получается оценка: $|R| \le \frac{(b-a)^3}{24} M_2$.

**2. Вывод для формулы трапеций**
Аналогично вводится $R(h) = \int f(t)dt - h(f(\theta-h) + f(\theta+h))$.
После взятия производных оказывается, что первая ненулевая производная ошибки связана со второй производной функции $f''$.
Итог: $R = - \frac{(b-a)^3}{12} f''(\xi)$.

**3. Вывод для формулы Симпсона**
Здесь $R(0)=0, R'(0)=0, R''(0)=0$.
Только третья производная ошибки $R'''(h)$ дает нетривиальный результат.
В процессе вывода используется разложение:
$$R'''(h) = -\frac{h}{3} (f'''(\theta+h) - f'''(\theta-h))$$
Применяя теорему Лагранжа к разности третьих производных, получаем четвертую производную $f^{(4)}(\xi)$.
Это объясняет высокий порядок точности метода Симпсона.

---

### Билет 13. Свойства кубических сплайнов и Теорема о минимальной кривизне

**1. Экстремальное свойство сплайна**
Среди всех функций $F(x)$, проходящих через заданные точки $(x_i, y_i)$ и имеющих непрерывную вторую производную, кубический сплайн $S(x)$ доставляет **минимум функционалу энергии (кривизны)**:
$$J(F) = \int_a^b (F''(x))^2 dx \to \min$$
Это свойство физически соответствует поведению гибкой упругой линейки, закрепленной в узлах (отсюда название "сплайн" — рейка).

**2. Доказательство (схема)**
Рассматривается произвольная функция $F(x)$, проходящая через узлы. Она представляется как $F(x) = S(x) + \delta(x)$, где $\delta(x_i) = 0$.
Интеграл раскрывается как:
$$\int (S'' + \delta'')^2 dx = \int (S'')^2 dx + 2\int S'' \delta'' dx + \int (\delta'')^2 dx$$
Ключевой момент доказательства: показать, что среднее слагаемое $\int S'' \delta'' dx = 0$ (используя интегрирование по частям и свойства линейности второй производной сплайна).
Тогда $\int (F'')^2 = \int (S'')^2 + \int (\delta'')^2 \ge \int (S'')^2$.

---

### Билет 14. Ортогональные многочлены и Решение нелинейных уравнений (обзор)

**1. Многочлены Лежандра $L_n(x)$**
Используются для построения формул Гаусса на отрезке $[-1, 1]$.
Определяются формулой Родрига или рекуррентно.
*   $L_0(x) = 1$
*   $L_1(x) = x$
*   $L_2(x) = \frac{1}{2}(3x^2 - 1)$
*Свойства:*
1.  Все $n$ корней полинома $L_n(x)$ — вещественные, различные и лежат внутри интервала $(-1, 1)$.
2.  Корни расположены симметрично относительно нуля.
3.  Ортогональность: $\int_{-1}^1 L_n(x) L_m(x) dx = 0$, если $n \ne m$.

**2. Методы решения нелинейных уравнений $f(x)=0$**
В конце лекций приведен краткий список методов:
1.  **Метод перебора:** разбиение на мелкие отрезки и проверка смены знака.
2.  **Метод половинного деления (бисекция):**
    Если $f(a)f(b) < 0$, делим отрезок пополам $c = (a+b)/2$. Выбираем ту половину, где знаки на концах разные. Сходимость медленная, но гарантированная.
3.  **Метод хорд:**
    Точки $a$ и $b$ соединяются прямой. Новое приближение — точка пересечения хорды с осью $X$.
4.  **Метод Ньютона (касательных):**
    $x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$.
    Очень быстрая (квадратичная) сходимость вблизи корня, но требует знания производной и хорошего начального приближения.

**3. Проблема собственных значений**
*   Определение: Найти $\lambda$ и вектор $V \ne 0$, такие что $AV = \lambda V$.
*   Характеристическое уравнение: $\det(A - \lambda E) = 0$.
*   В лекциях упомянут **Степенной метод** (Iterative method) для нахождения максимального по модулю собственного числа: $x_{k+1} = A x_k$. Отношение компонент векторов сходится к $\lambda_{max}$.
---

### Билет 15. Численное интегрирование. Методы прямоугольников

**1. Постановка задачи**
Требуется вычислить определенный интеграл $I = \int_a^b f(x) dx$.
Если первообразная не выражается в элементарных функциях или функция задана таблично, используют численные методы (квадратурные формулы).
Отрезок $[a, b]$ разбивается на $N$ частей (шаг $h = \frac{b-a}{N}$ или произвольный $\Delta x_i$).
Интеграл заменяется интегральной суммой Римана:
$$I \approx S_N = \sum_{i=1}^N f(\xi_i) \Delta x_i$$

**2. Виды формул прямоугольников**
Для элементарного отрезка (одного шага) интеграл приближают площадью прямоугольника.
*   **Формула левых прямоугольников:**
    $\xi_i = x_{i-1}$ (левый край).
    $I \approx \sum_{i=1}^N f(x_{i-1}) h$.
    Погрешность одного шага $\sim O(h^2)$, суммарная погрешность на всем отрезке $\sim O(h)$.
*   **Формула правых прямоугольников:**
    $\xi_i = x_i$ (правый край).
    Аналогично, точность первого порядка $O(h)$.
*   **Формула средних прямоугольников:**
    $\xi_i = \frac{x_{i-1} + x_i}{2}$ (середина отрезка).
    $I \approx \sum_{i=1}^N f\left(\frac{x_{i-1} + x_i}{2}\right) h$.
    За счет симметрии (взятие точки в центре) точность повышается.
    Алгебраическая степень точности $m=1$ (точна для линейных функций $ax+b$).
    Суммарная погрешность порядка $O(h^2)$.

---

### Билет 16. Интерполяционные квадратурные формулы (Ньютона-Котеса)

**1. Общий принцип**
Идея: заменить подынтегральную функцию $f(x)$ на интерполяционный многочлен Лагранжа $P_n(x)$, построенный на равномерной сетке узлов, и проинтегрировать его точно.
$$I \approx \int_a^b P_n(x) dx = \int_a^b \sum_{k=0}^n y_k L_k(x) dx = \sum_{k=0}^n y_k \left( \int_a^b L_k(x) dx \right)$$
Величины $w_k = \int_a^b L_k(x) dx$ называются **весами** квадратурной формулы. Они не зависят от функции $f(x)$.

**2. Основные формулы (для элементарного отрезка)**
*   **Формула трапеций ($n=1$, 2 узла $a, b$):**
    Замена $f(x)$ на хорду (прямую).
    $\int_a^b f(x) dx \approx \frac{b-a}{2} (f(a) + f(b))$.
    Веса: $\frac{1}{2}, \frac{1}{2}$ (умноженные на длину отрезка).
*   **Формула Симпсона ($n=2$, 3 узла $a, \frac{a+b}{2}, b$):**
    Замена $f(x)$ на параболу.
    $\int_a^b f(x) dx \approx \frac{b-a}{6} \left( f(a) + 4f(\frac{a+b}{2}) + f(b) \right)$.
    Веса: $\frac{1}{6}, \frac{4}{6}, \frac{1}{6}$.
    *Примечание:* часто записывают через шаг $h = \frac{b-a}{2}$, тогда $I \approx \frac{h}{3}(f_0 + 4f_1 + f_2)$.
*   **Правило «3/8» ($n=3$, 4 узла):**
    $\int_a^b f(x) dx \approx \frac{b-a}{8} (f(a) + 3f(x_1) + 3f(x_2) + f(b))$.

**3. Составные формулы**
Формулы применяются к каждому подотрезку разбиения и суммируются.
Например, составная формула Симпсона:
$I \approx \frac{h}{3} [f(a) + f(b) + 4\sum f_{\text{нечет}} + 2\sum f_{\text{чет}}]$.

---

### Билет 17. Алгебраическая степень точности (АСТ)

**1. Определение**
Квадратурная формула имеет алгебраическую степень точности $m$, если она **точно** интегрирует все многочлены степени не выше $m$ ($1, x, \dots, x^m$), но не интегрирует точно многочлены степени $m+1$.

**2. Теорема (Критерий АСТ)**
Для того чтобы формула $\sum w_k f(x_k)$ имела степень $m$, необходимо и достаточно, чтобы она была точна для базисных мономов $x^k, k=0..m$.
Это позволяет находить веса $w_k$ (метод неопределенных коэффициентов), решая систему уравнений:

$$
\begin{cases} 
\sum w_k = \int 1 dx = b-a \\ 
\sum w_k x_k = \int x dx \\ 
\dots \\ 
\sum w_k x_k^m = \int x^m dx 
\end{cases}
$$

**3. Связь числа узлов и степени**
Интерполяционная формула, построенная по $n+1$ узлу, гарантированно имеет АСТ не ниже $n$.
Однако для формул Ньютона-Котеса с **четным** числом шагов (нечетным числом узлов, например, Симпсон: 3 узла) степень точности повышается на 1.
*   Трапеции (2 узла): $m=1$.
*   Симпсон (3 узла): $m=3$ (хотя интерполируем параболой степени 2, формула точна для кубов).
*   Правило 3/8 (4 узла): $m=3$.

---

### Билет 18. Остаточный член квадратурных формул

**1. Понятие остаточного члена**
Обозначим $E[f] = \int_a^b f(x) dx - \sum w_k f(x_k)$. Это ошибка интегрирования (линейный функционал).
Если формула имеет АСТ $m$, то $E[P_m] = 0$.

**2. Вывод оценки (через ядро Пеано/ряд Тейлора)**
Представим $f(x)$ по формуле Тейлора с остаточным членом в интегральной форме:
$f(x) = P_m(x) + R_m(x)$.
Так как формула точна для полинома $P_m$, то ошибка $E[f] = E[R_m]$.
После преобразований (замена порядка интегрирования и суммирования) ошибка приводится к виду:
$$E[f] = \int_a^b f^{(m+1)}(t) Q(t) dt$$
где $Q(t)$ — так называемое ядро ошибки (зависит только от вида формулы и узлов).

**3. Оценки**
Если $Q(t)$ не меняет знак на отрезке (как в правиле Симпсона или трапеций), применяется теорема о среднем:
$$E[f] = \frac{f^{(m+1)}(\xi)}{(m+1)!} C, \quad \text{где } C = \text{const}$$
*   Для трапеций: $|E| \le \frac{M_2 (b-a)^3}{12}$.
*   Для Симпсона: $|E| \le \frac{M_4 (b-a)^5}{2880}$ (здесь степень повысилась, нужна 4-я производная).
Если $Q(t)$ меняет знак, оценка грубее: $|E| \le M_{m+1} \int |Q(t)| dt$.

---

### Билет 19. Правило Рунге (Апостериорная оценка погрешности)

**1. Идея метода**
Априорные оценки (через максимум производной $M_n$) часто неудобны, так как сложно оценить высшую производную сложной функции.
Правило Рунге позволяет оценить ошибку **в процессе вычислений**, используя результаты на сетках с разным шагом.

**2. Разложение ошибки**
Пусть метод имеет порядок точности  $p$ ( ошибка $\sim O(h^p)$ ) . Тогда точное значение интеграла $I^*$ можно записать как:

$$I^* = I_h + C \cdot h^p + O(h^{p+1})$$

Вычислим интеграл на сетке с шагом $h/2$:
$$I^* = I_{h/2} + C \cdot \left(\frac{h}{2}\right)^p + \dots$$

**3. Формула Рунге**
Вычитая уравнения и пренебрегая членами высших порядков, находим главный член погрешности для мелкой сетки:
$$E_{h/2} \approx \frac{I_{h/2} - I_h}{2^p - 1}$$
*   Для трапеций ($p=2$): ошибка $\approx \frac{I_{h/2} - I_h}{3}$.
*   Для Симпсона ($p=4$): ошибка $\approx \frac{I_{h/2} - I_h}{15}$.

**4. Контроль порядка сходимости**
Если фактический порядок сходимости отличается от теоретического (из-за негладкости функции), его можно оценить численно:
$$p^* \approx \log_2 \frac{I_h - I_{h/2}}{I_{h/2} - I_{h/4}}$$

---

### Билет 20. Ортогональные многочлены (Лежандра)

**1. Определение ортогональности**
Система многочленов $\{L_k(x)\}$ называется ортогональной на отрезке $[a, b]$ с весом $\rho(x)$ (обычно $\rho=1$), если:
$$\int_a^b L_n(x) L_m(x) \rho(x) dx = 0 \quad \text{при } n \ne m$$

**2. Построение (Процесс ортогонализации)**
Строятся из системы $1, x, x^2, \dots$ методом Грама-Шмидта.
Требуем, чтобы $L_n(x)$ был ортогонален всем многочленам степени меньше $n$.

**3. Многочлены Лежандра (на $[-1, 1]$)**
Это классический пример ортогональных многочленов ($\rho=1$).
*   $L_0(x) = 1$
*   $L_1(x) = x$
*   $L_2(x) = x^2 - \frac{1}{3}$ (или в нормировке $3x^2-1$).
*   $L_3(x) = x^3 - \frac{3}{5}x$.
*Свойство корней:* У полинома $L_n(x)$ ровно $n$ простых вещественных корней, и все они лежат внутри интервала $(-1, 1)$. Эти корни используются как узлы в квадратуре Гаусса.

---

### Билет 21. Квадратурные формулы Гаусса

**1. Максимальная степень точности**
В формулах Ньютона-Котеса узлы фиксированы, варьируются только веса ( $n$ параметров $\to$ степень $n$).
В формулах Гаусса мы ищем и веса $w_k$, и узлы $x_k$.
Всего $2n$ параметров. Это позволяет достичь алгебраической степени точности $2n-1$.

**2. Теорема о выборе узлов**
Интеграл будет вычислен точно для многочлена степени $2n-1$, если в качестве узлов $x_k$ взять **корни ортогонального многочлена** степени $n$ (полинома Лежандра для отрезка $[-1, 1]$).

**3. Таблица узлов и весов (для $[-1, 1]$)**
*   **1 узел ($n=1$):** $x_1 = 0, w_1 = 2$. Формула: $I \approx 2 f(0)$. Точна для линейных функций. (Совпадает со средней точкой).
*   **2 узла ($n=2$):** Корни $L_2(x) = 3x^2 - 1 \Rightarrow x_{1,2} = \pm \frac{1}{\sqrt{3}}$.
    Веса $w_1 = w_2 = 1$.
    $I \approx f(-\frac{1}{\sqrt{3}}) + f(\frac{1}{\sqrt{3}})$. Точна для кубических многочленов ($2\cdot 2 - 1 = 3$).
*   **3 узла ($n=3$):** Узлы $0, \pm \sqrt{\frac{3}{5}}$. Веса: $8/9$ для центра, $5/9$ для краев. Точна для степени 5.

Остаточный член формулы Гаусса содержит производную порядка $2n$, что дает очень высокую точность.

---

### Билет 22. Вывод формул погрешности интегрирования (Детальный анализ)

В лекциях приведен вывод остаточных членов $R(h)$ для простых формул методом **дифференцирования по параметру** (длине отрезка).

**1. Формула средней точки**
Пусть $I(h) = \int_{\theta-h}^{\theta+h} f(t) dt$ (интеграл по отрезку длины $2h$).
Приближение $I_{cp} = 2h f(\theta)$.
Ошибка $R(h) = I(h) - 2h f(\theta)$.
$R(0) = 0$.
$R'(h) = f(\theta+h) + f(\theta-h) - 2f(\theta)$.
$R''(h) = f'(\theta+h) - f'(\theta-h) = 2h f''(\xi)$ (по т. Лагранжа).
Интегрируя дважды (или через разложение Тейлора), получаем $R(h) \approx \frac{2}{3} h^3 f''(\xi)$.
Переходя к длине отрезка $(b-a)$, получаем коэффициент $1/24$.

**2. Формула Симпсона**
Аналогично вводится функция ошибки от полушага $h$.
$R(h) = \int_{\theta-h}^{\theta+h} f(t)dt - \frac{h}{3}(f(\theta-h) + 4f(\theta) + f(\theta+h))$.
Последовательно дифференцируем по $h$.
Первая, вторая производные обращаются в ноль в точке $h=0$.
Третья производная $R'''(h)$ оказывается первой, не равной тождественно нулю. Она пропорциональна разности третьих производных, что сводится к 4-й производной $f^{(4)}$.
Это доказывает, что метод имеет 4-й порядок точности (или 3-ю алгебраическую степень точности, так как ошибка зависит от 4-й производной).

---

### Билет 23. Проблема собственных значений и Нелинейные уравнения

**1. Проблема собственных значений**
Для квадратной матрицы $A$ требуется найти число $\lambda$ и ненулевой вектор $V$, такие что:
$$AV = \lambda V \implies (A - \lambda E)V = 0$$
Чтобы существовал ненулевой вектор $V$, матрица $(A - \lambda E)$ должна быть вырожденной.
$$\det(A - \lambda E) = 0$$
Это уравнение называется **характеристическим**. Его корни — собственные числа.

**2. Численное решение нелинейных уравнений**
Задача: найти корни $f(x) = 0$.
Этапы:
1.  **Локализация корней:** нахождение отрезков, содержащих только один корень (например, таблично или графически, или методом перебора с шагом).
2.  **Уточнение корней:** итерационные методы.
    *   *Метод бисекции (дихотомии):* деление отрезка пополам. Надежен, но сходится медленно (линейно).
    *   *Метод хорд:* линейная интерполяция по двум концам.
    *   *Метод Ньютона (касательных):* строится касательная в точке приближения. Сходится квадратично (очень быстро), но может расходиться при плохом начальном выборе.

**3. Связь с корректностью**
В лекции отмечено (из практических задач), что нахождение корней полинома высоких степеней может быть **плохо обусловленной** задачей (малые изменения коэффициентов сильно меняют корни, пример многочлена Уилкинсона).
